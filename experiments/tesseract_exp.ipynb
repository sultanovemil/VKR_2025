{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JdkQb8fIhCD_",
        "OTY_lHlYgOxl",
        "MBVZPp1zgPPl"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Эксперименты с Tesseract 5 по распознаванию удостоверений на тестовой выборке"
      ],
      "metadata": {
        "id": "WtgM-eerfqvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценка работы на тестовом датасете"
      ],
      "metadata": {
        "id": "JdkQb8fIhCD_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1flM6pArfXy_"
      },
      "outputs": [],
      "source": [
        "# Устанавливаем библиотеки\n",
        "!sudo apt remove -y tesseract-ocr\n",
        "!sudo apt autoremove -y\n",
        "!sudo apt update\n",
        "!sudo apt install -y software-properties-common\n",
        "!sudo add-apt-repository -y ppa:alex-p/tesseract-ocr-devel  # Репозиторий с Tesseract 5\n",
        "!sudo apt update\n",
        "!sudo apt install -y tesseract-ocr libtesseract-dev\n",
        "!sudo apt install -y tesseract-ocr-rus tesseract-ocr-eng  # Основные языки\n",
        "!pip install pytesseract\n",
        "!pip install python-Levenshtein tqdm opencv-python-headless -q\n",
        "\n",
        "# Импорт библиотек\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.drawing.image import Image as ExcelImage\n",
        "from PIL import Image as PILImage\n",
        "import io\n",
        "\n",
        "# Установка пути к данным Tesseract\n",
        "os.environ['TESSDATA_PREFIX'] = '/usr/share/tesseract-ocr/5/tessdata/'\n",
        "\n",
        "def preprocess_image(image):\n",
        "    \"\"\"\n",
        "    Предобработка изображения: конвертация в оттенки серого.\n",
        "\n",
        "    Args:\n",
        "        image (numpy.ndarray): Входное изображение в формате BGR или grayscale.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Изображение в оттенках серого.\n",
        "    \"\"\"\n",
        "    #Конвертация в grayscale\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image.copy()\n",
        "\n",
        "    return gray\n",
        "\n",
        "# Настройки путей\n",
        "IMAGES_DIR = '/content/drive/MyDrive/VKR/kpk_dataset-9/test/images'\n",
        "LABELS_DIR = '/content/drive/MyDrive/VKR/kpk_dataset-9/test/labels'\n",
        "JSON_PATH = '/content/drive/MyDrive/VKR/kpk_dataset-9/test_annotations.json'\n",
        "EXCEL_PATH = '/content/drive/MyDrive/VKR/results/results_optimized.xlsx'\n",
        "DEBUG_DIR = '/content/drive/MyDrive/VKR/results/debug_images'\n",
        "TEMP_IMG_DIR = '/content/drive/MyDrive/VKR/results/temp_images'\n",
        "os.makedirs(DEBUG_DIR, exist_ok=True)\n",
        "os.makedirs(TEMP_IMG_DIR, exist_ok=True)\n",
        "\n",
        "# Сопоставление классов с их названиями\n",
        "CLASS_MAPPING = {\n",
        "    0: \"city\",\n",
        "    1: \"course_period\",\n",
        "    2: \"course_topic\",\n",
        "    3: \"hours\",\n",
        "    4: \"name\",\n",
        "    5: \"organization\",\n",
        "    6: \"registration_number\",\n",
        "    7: \"year\"\n",
        "}\n",
        "\n",
        "def load_annotations(json_path):\n",
        "    \"\"\"\n",
        "    Загрузка аннотаций из JSON-файла.\n",
        "\n",
        "    Args:\n",
        "        json_path (str): Путь к JSON-файлу с аннотациями.\n",
        "\n",
        "    Returns:\n",
        "        dict: Словарь с аннотациями для каждого изображения.\n",
        "    \"\"\"\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    return {os.path.splitext(item['file_name'])[0]: item['annotations'] for item in data['images']}\n",
        "\n",
        "def read_yolo_bboxes(label_path, img_width, img_height):\n",
        "    \"\"\"\n",
        "    Чтение bounding box из файла в формате YOLO.\n",
        "\n",
        "    Args:\n",
        "        label_path (str): Путь к файлу с разметкой.\n",
        "        img_width (int): Ширина изображения.\n",
        "        img_height (int): Высота изображения.\n",
        "\n",
        "    Returns:\n",
        "        list: Список bounding box в формате (class_id, (x1, y1, x2, y2)).\n",
        "    \"\"\"\n",
        "    if not os.path.exists(label_path):\n",
        "        return []\n",
        "\n",
        "    bboxes = []\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue\n",
        "\n",
        "            class_id, x_center, y_center, width, height = map(float, parts)\n",
        "            x1 = int((x_center - width/2) * img_width)\n",
        "            y1 = int((y_center - height/2) * img_height)\n",
        "            x2 = int((x_center + width/2) * img_width)\n",
        "            y2 = int((y_center + height/2) * img_height)\n",
        "            bboxes.append((int(class_id), (x1, y1, x2, y2)))\n",
        "    return bboxes\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Очистка текста: удаление лишних пробелов и переносов строк.\n",
        "\n",
        "    Args:\n",
        "        text (str): Входной текст.\n",
        "\n",
        "    Returns:\n",
        "        str: Очищенный текст.\n",
        "    \"\"\"\n",
        "    return ' '.join(text.replace('\\n', ' ').replace('\\r', ' ').split()).strip()\n",
        "\n",
        "\n",
        "def save_image_to_temp(image, filename):\n",
        "   \"\"\"\n",
        "    Сохранение изображения во временную директорию.\n",
        "\n",
        "    Args:\n",
        "        image (numpy.ndarray): Изображение для сохранения.\n",
        "        filename (str): Имя файла.\n",
        "\n",
        "    Returns:\n",
        "        str: Путь к сохраненному файлу.\n",
        "    \"\"\"\n",
        "    temp_path = os.path.join(TEMP_IMG_DIR, filename)\n",
        "    cv2.imwrite(temp_path, image)\n",
        "    return temp_path\n",
        "\n",
        "def process_image_with_stats(image_path, label_path, annotations, debug=False):\n",
        "    \"\"\"\n",
        "    Обработка изображения: распознавание текста и расчет метрик.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Путь к изображению.\n",
        "        label_path (str): Путь к файлу с разметкой.\n",
        "        annotations (dict): Аннотации для изображений.\n",
        "        debug (bool): Флаг отладки.\n",
        "\n",
        "    Returns:\n",
        "        list: Список результатов распознавания.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        return []\n",
        "\n",
        "    image_id = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    img_height, img_width = image.shape[:2]\n",
        "    bboxes = read_yolo_bboxes(label_path, img_width, img_height)\n",
        "\n",
        "    results = []\n",
        "    for i, (class_id, bbox) in enumerate(bboxes):\n",
        "        field_name = CLASS_MAPPING.get(class_id, f\"Class {class_id}\")\n",
        "        cropped = image[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
        "\n",
        "        # Сохраняем изображение до обработки\n",
        "        original_img_path = save_image_to_temp(cropped, f\"{image_id}_{i}_original.png\")\n",
        "\n",
        "        # Обработка изображения\n",
        "        processed = preprocess_image(cropped)\n",
        "\n",
        "        # Сохраняем изображение после обработки\n",
        "        processed_img_path = save_image_to_temp(processed, f\"{image_id}_{i}_processed.png\")\n",
        "\n",
        "        # Распознавание\n",
        "        text = pytesseract.image_to_string(processed, lang='rus+eng')\n",
        "        recognized_text = clean_text(text)\n",
        "        reference_text = clean_text(annotations.get(image_id, {}).get(field_name, \"\"))\n",
        "        cer = calculate_cer(reference_text, recognized_text)\n",
        "\n",
        "        results.append({\n",
        "            \"image_id\": image_id,\n",
        "            \"class\": field_name,\n",
        "            \"reference\": reference_text,\n",
        "            \"recognized\": recognized_text,\n",
        "            \"cer\": cer,\n",
        "            \"original_image\": original_img_path,\n",
        "            \"processed_image\": processed_img_path\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "def calculate_cer(reference, hypothesis):\n",
        "    \"\"\"\n",
        "    Расчет Character Error Rate (CER).\n",
        "\n",
        "    Args:\n",
        "        reference (str): Эталонный текст.\n",
        "        hypothesis (str): Распознанный текст.\n",
        "\n",
        "    Returns:\n",
        "        float: Значение CER.\n",
        "    \"\"\"\n",
        "    if not reference:\n",
        "        return 0.0 if not hypothesis else 1.0\n",
        "    return levenshtein_distance(reference, hypothesis) / max(len(reference), 1)\n",
        "\n",
        "def main():\n",
        "    annotations = load_annotations(JSON_PATH)\n",
        "    image_files = [f for f in os.listdir(IMAGES_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    all_results = []\n",
        "    for i, image_file in enumerate(image_files[:15]):  # Ограничиваем для теста\n",
        "        image_path = os.path.join(IMAGES_DIR, image_file)\n",
        "        label_path = os.path.join(LABELS_DIR, os.path.splitext(image_file)[0] + \".txt\")\n",
        "\n",
        "        print(f\"Обработка {i+1}/{len(image_files)}: {image_file}\")\n",
        "        results = process_image_with_stats(\n",
        "            image_path, label_path, annotations,\n",
        "            debug=(i < 3)  # Отладка для первых 3 изображений\n",
        "        )\n",
        "        all_results.extend(results)\n",
        "\n",
        "    # Создаем DataFrame\n",
        "    df = pd.DataFrame(all_results)\n",
        "\n",
        "    # Создаем Excel файл с изображениями\n",
        "    wb = Workbook()\n",
        "    ws = wb.active\n",
        "    ws.title = \"Results\"\n",
        "\n",
        "    # Заголовки\n",
        "    headers = [\"Image ID\", \"Class\", \"Reference Text\", \"Recognized Text\", \"CER\", \"Original Image\", \"Processed Image\"]\n",
        "    ws.append(headers)\n",
        "\n",
        "    # Добавляем данные и изображения\n",
        "    for idx, row in df.iterrows():\n",
        "        ws.append([\n",
        "            row[\"image_id\"],\n",
        "            row[\"class\"],\n",
        "            row[\"reference\"],\n",
        "            row[\"recognized\"],\n",
        "            row[\"cer\"],\n",
        "            \"\",  # Место для изображения\n",
        "            \"\"   # Место для изображения\n",
        "        ])\n",
        "\n",
        "        # Добавляем оригинальное изображение\n",
        "        if os.path.exists(row[\"original_image\"]):\n",
        "            img = ExcelImage(row[\"original_image\"])\n",
        "            img.width = 100\n",
        "            img.height = 100\n",
        "            ws.add_image(img, f'F{idx + 2}')\n",
        "\n",
        "        # Добавляем обработанное изображение\n",
        "        if os.path.exists(row[\"processed_image\"]):\n",
        "            img = ExcelImage(row[\"processed_image\"])\n",
        "            img.width = 100\n",
        "            img.height = 100\n",
        "            ws.add_image(img, f'G{idx + 2}')\n",
        "\n",
        "    # Сохраняем Excel файл\n",
        "    wb.save(EXCEL_PATH)\n",
        "\n",
        "    # Анализ результатов\n",
        "    print(\"\\nОбщая статистика CER:\")\n",
        "    print(f\"Средний: {df['cer'].mean():.4f}\")\n",
        "    print(f\"Медиана: {df['cer'].median():.4f}\")\n",
        "\n",
        "    print(\"\\nПо классам:\")\n",
        "    print(df.groupby('class')['cer'].mean().sort_values())\n",
        "\n",
        "    print(f\"\\nРезультаты сохранены в {EXCEL_PATH}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценка времени"
      ],
      "metadata": {
        "id": "OTY_lHlYgOxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт библиотек\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import pytesseract\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "\n",
        "# Конфигурация путей\n",
        "IMAGES_DIR = '/content/drive/MyDrive/VKR/kpk_dataset-9/test/images'\n",
        "LABELS_DIR = '/content/drive/MyDrive/VKR/kpk_dataset-9/test/labels'\n",
        "JSON_PATH = '/content/drive/MyDrive/VKR/kpk_dataset-9/test_annotations.json'\n",
        "RESULTS_DIR = '/content/drive/MyDrive/VKR/results/tesseract'\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "CLASS_MAPPING = {\n",
        "    0: \"city\",\n",
        "    1: \"course_period\",\n",
        "    2: \"course_topic\",\n",
        "    3: \"hours\",\n",
        "    4: \"name\",\n",
        "    5: \"organization\",\n",
        "    6: \"registration_number\",\n",
        "    7: \"year\"\n",
        "}\n",
        "\n",
        "def load_annotations(json_path):\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    return {os.path.splitext(item['file_name'])[0]: item['annotations'] for item in data['images']}\n",
        "\n",
        "def read_yolo_bboxes(label_path, img_width, img_height):\n",
        "    if not os.path.exists(label_path):\n",
        "        return []\n",
        "    bboxes = []\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue\n",
        "            class_id, x_center, y_center, width, height = map(float, parts)\n",
        "            x1 = int((x_center - width/2) * img_width)\n",
        "            y1 = int((y_center - height/2) * img_height)\n",
        "            x2 = int((x_center + width/2) * img_width)\n",
        "            y2 = int((y_center + height/2) * img_height)\n",
        "            bboxes.append((int(class_id), (x1, y1, x2, y2)))\n",
        "    return bboxes\n",
        "\n",
        "def process_image_tesseract(image_path, label_path, annotations):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        return []\n",
        "\n",
        "    image_id = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    img_height, img_width = image.shape[:2]\n",
        "    bboxes = read_yolo_bboxes(label_path, img_width, img_height)\n",
        "\n",
        "    results = []\n",
        "    for class_id, bbox in bboxes:\n",
        "        field_name = CLASS_MAPPING.get(class_id, f\"Class {class_id}\")\n",
        "        cropped = image[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
        "\n",
        "        # Предобработка\n",
        "        gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Замер времени\n",
        "        start_time = time.time()\n",
        "        recognized_text = pytesseract.image_to_string(cropped, lang='rus+eng')\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        recognized_text = recognized_text.strip()\n",
        "        reference_text = annotations.get(image_id, {}).get(field_name, \"\")\n",
        "\n",
        "        results.append({\n",
        "            'image_id': image_id,\n",
        "            'class': field_name,\n",
        "            'time': elapsed,\n",
        "            'cer': levenshtein_distance(reference_text, recognized_text) / max(len(reference_text), 1)\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "def main_tesseract():\n",
        "    \"\"\"\n",
        "    Функция для оценки времени работы Tesseract.\n",
        "    \"\"\"\n",
        "    annotations = load_annotations(JSON_PATH)\n",
        "    image_files = [f for f in os.listdir(IMAGES_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    print(f\"Начато тестирование Tesseract на {len(image_files)} изображениях\")\n",
        "\n",
        "    all_results = []\n",
        "    for img_file in tqdm(image_files):\n",
        "        image_path = os.path.join(IMAGES_DIR, img_file)\n",
        "        label_path = os.path.join(LABELS_DIR, os.path.splitext(img_file)[0] + \".txt\")\n",
        "\n",
        "        results = process_image_tesseract(image_path, label_path, annotations)\n",
        "        all_results.extend(results)\n",
        "\n",
        "    # Сохранение и анализ результатов\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.to_csv(os.path.join(RESULTS_DIR, 'tesseract_results.csv'), index=False)\n",
        "\n",
        "    print(\"\\nРезультаты Tesseract:\")\n",
        "    print(f\"Общее время: {df['time'].sum():.2f} сек\")\n",
        "    print(f\"Среднее время: {df['time'].mean():.4f} сек/изображение\")\n",
        "    print(f\"Средний CER: {df['cer'].mean():.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_tesseract()\n"
      ],
      "metadata": {
        "id": "-XLR26k0gOYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Интервальная оценка CER для Tesseract"
      ],
      "metadata": {
        "id": "MBVZPp1zgPPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт библиотек\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "RESULTS_DIR = '/content/drive/MyDrive/VKR/results/tesseract'\n",
        "\n",
        "def calculate_confidence_interval_tesseract():\n",
        "    \"\"\"\n",
        "    Функция для расчета доверительного интервала CER.\n",
        "    \"\"\"\n",
        "    # Загрузка результатов\n",
        "    df = pd.read_csv(os.path.join(RESULTS_DIR, 'tesseract_results.csv'))\n",
        "\n",
        "    # Удаление нулевых строк (если есть проблемы с данными)\n",
        "    df = df[df['cer'].notna()]\n",
        "\n",
        "    # Расчет параметров\n",
        "    mean_cer = df['cer'].mean()\n",
        "    std_cer = df['cer'].std()\n",
        "    n = len(df)\n",
        "\n",
        "    # 95% доверительный интервал\n",
        "    confidence = 0.95\n",
        "    se = std_cer / np.sqrt(n)\n",
        "    ci = stats.t.interval(confidence, n-1, loc=mean_cer, scale=se)\n",
        "\n",
        "    print(\"\\nИнтервальная оценка CER для Tesseract:\")\n",
        "    print(f\"Средний CER: {mean_cer:.4f}\")\n",
        "    print(f\"Стандартное отклонение: {std_cer:.4f}\")\n",
        "    print(f\"95% доверительный интервал: ({ci[0]:.4f}, {ci[1]:.4f})\")\n",
        "    print(f\"Количество образцов: {n}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    calculate_confidence_interval_tesseract()"
      ],
      "metadata": {
        "id": "SXmU3LhPg2xG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}